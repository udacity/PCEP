{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1NRp1xx165sUo75fDmH8VQTIgve6PnoFh","timestamp":1719482921883}],"collapsed_sections":["6hluV00Utlc-","9ZRnadOTrpvc"],"authorship_tag":"ABX9TyN1X8YsvLtMbtfADHAjLJEy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Transformational AI: Analyzing Ecommerce Large Datasets for Machine Learning\n","\n","Welcome to your journey as a data scientist at Transformational AI, where you will play a pivotal role in shaping the future of our company's machine learning models. In this project, you will leverage two Amazon Reviews 2023 datasets, originally sourced from Hugging Face, to perform data transformation, analysis, and visualization. Through this notebook, you will gain hands-on experience with pandas DataFrames and explore powerful data visualization techniques using `seaborn` and `matplotlib`. You will also learn to export your cleaned and processed data into `.csv` and `.parquet` formats, ready for advanced machine learning tasks. Get ready to dive into the world of data science and make impactful contributions to our machine learning team by preparing top-quality datasets for model fine-tuning and customer satisfaction analysis.\n","\n","Do not worry if this sounds like a lot right now. Transformational AI makes no mistakes and we hired you for a reason. We will take this one step at a time, and know you have our full support every step of the way. We will be using a lot of advanced language and words, which will add to your Pythonic knowledge and background, while, reinforcing core concepts that you will need to know for your upcoming PCEP exam.\n","\n","We know you can do it and we cannot wait to see what you create. Let‚Äôs get started!"],"metadata":{"id":"1bws_jMEkgSI"}},{"cell_type":"markdown","source":["# Part 1: Preparing the Environment"],"metadata":{"id":"Cq4Hhtw1sd7B"}},{"cell_type":"markdown","source":["## Part 1.1: Learn about Jupyter Notebooks & Python Virtual Environments\n","\n","When working with Python for a company, organization, or personal project, it's essential to initialize your Python environment properly. Remember from the course the concept of a Python \"virtual environment.\" This isolated environment allows you to write functions, store variables, work with data, and perform many other operations without interfering with other projects or the system Python environment.\n","\n","In this step, we will set up and use the Python environment within Jupyter Notebook, which is an interactive computing environment. This will assist us in our tasks at Transformational AI, enabling us to efficiently manage and analyze data, write and test code, and visualize results.\n","\n","If you remember from course, Python is a versioned language, and software packages are versioned as well. Let's check out which version of Python is installed thanks to our Jupyter Notebook and also let's check which version of Jupyter Notebook is installed here for us to use as well.\n","\n","Run the following commands to check these values:"],"metadata":{"id":"x5hAovwbu_SL"}},{"cell_type":"code","source":["# Check which version of Python is installed\n","!python --version\n","\n","# Check which version of Jupyter Notebook you are using\n","!jupyter-notebook --version"],"metadata":{"id":"FiHPOfuBvf48"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Part 1.2: Set Up the Jupyter Notebook\n","\n","To get started, we need to ensure that our Jupyter Notebook environment is equipped with the necessary libraries to run what we need to run. These libraries will help us manage data, create visualizations, and interact with our notebook more effectively.\n","\n","For your work in this notebook, you will need the following packages:\n","\n","- `datasets`: Providres access to a wide range of datasets, including the Amazon Reviews 2023 dataset we'll be using.\n","- `pandas`: A powerful data manipulation and analysis library that makes working with structured data easy with Python.\n","- `matplotlib`: A comprehensive library for creating static, animated, and interactive visualizations in Python.\n","- `seaborn`: Built on top of matplotlib, seaborn provides a high-level interface for drawing attractive and informative statistical graphics, great for visualizing trends from data.\n","- `ipywidgets`: Adds interactive widgets to your Jupyter notebooks, allowing for dynamic and interactive user interfaces. You will see various input fields throughout the notebook that leverages this package.\n","\n","üëâ Do not worry about memorizing these packages this for the PCEP exam. However, as you continue to build upon your Python skills moving forward, these packages will be great tools to have in your toolbox.\n","\n","Run a command to install these packages into the Jupyter Notebook envionment:"],"metadata":{"id":"WvLaWxoAtTri"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"4a9PoAVdimda"},"outputs":[],"source":["#<---- YOUR CODE GOES HERE ---->"]},{"cell_type":"markdown","source":["^ Note: If you see what looks like an error message that looks like this: `ERROR: pip's dependency resolver does not currently take into account all the packages that are installed....` do not worry. As long as you see this line printed at the end, you installed the packages successfully: `Successfully installed...`"],"metadata":{"id":"DI2N8oj_ujhK"}},{"cell_type":"markdown","source":["#### Solution"],"metadata":{"id":"6hluV00Utlc-"}},{"cell_type":"code","source":["!pip install datasets pandas matplotlib seaborn ipywidgets"],"metadata":{"id":"ERaLC91xtkU3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Part 2: Download the Reviews Dataset:"],"metadata":{"id":"v2t-mwCUL2b5"}},{"cell_type":"markdown","source":["## Part 2.1: Learn about Working with Big Data\n","\n","In this part, we will load the `Electronics` dataset using the Hugging Face datasets library into our Jupyter Notebook.\n","\n","### Working with large datasets:\n","\n","NOTE: We are working with a **BIG dataset**, so if we had all the time in the world, we could work through this **22.6 GB** into the notebook. However, we are in a time crunch and don't have time for you to utilize the entire dataset. We need to understand very quickly what products are the best, so let's take a subset of the dataset to use. Do not worry if it appears like the data is going slowly, this is just part of the data science. Consider going to get a cup of your favorite warm beverage ‚òïÔ∏è and coming back when it's done downloading.\n","\n","### Exploring DataFrames:\n","\n","To understand how to work with data in Python, `pandas` is a fantastic library that is widely used and very popular. In your work at Transformational AI, you will be using the `pandas` framework and to analyze the data in a `DataFrame`.\n","\n","You can think of `DataFrames` as a data structure packet that lets you work with data that could be in different formats or was from many different places, and has then been consolidated into a Pythonic, easy-to-work-with, structure. A `DataFrame` lets us do basic operations like viewing data, checking data types, and basic statistics, all within our Jupyter Notebook. How cool, right? üòé"],"metadata":{"id":"ErrFdd0UL6Sy"}},{"cell_type":"markdown","source":["## Part 2.2: Download and visualize the reviews dataset with `pandas`\n","\n","- For your first task at Transformational AI, we will be utilizing the `Electronics` dataset in order to help our machine learning engineers better understand what types of products are producing the most optimal customer engagement and attention.\n","\n","- While we could guess what products people like, Transformational AI is a data-driven company first and foremost. We will be relying on your to make data-informed decisions about which products are the most valuable for customers. The data you supply to the team will be very important for the training operations of their model outputs, so we will need to work quickly and diligently in order to make sure you can supply the ML team with the most optimal data possible.\n","\n","- When you work with software packages in Python, they will often come with a suite of options, or parameters, to tell the underlying core functions what to do. Sometimes, these inputs will be strings, booleans, integers, floats, or other types of data type inputs.\n","\n","- First, you will be loading into your Jupyter Notebook an Amazon Reviews dataset from 2023. In order to move quickly, we will only be pulling the first 100 items. After all, we don't have all day and have a very important deadline to meet this week. Speed is of the essence.\n","- You will load the data incrementally into a `pandas` DataFrame that will be set with a hard limit of 100 items in a for loop.\n","- Additionally, the `load_dataset` module will need edits to input the right parameters, in this case, boolean values for `streaming` and `trust_remote_code`.\n","  - You do not need to know what these parameters are doing behind the scenes, but the underlying boolean operators will tell the `datasets` package what to do - a great use of boolean operators here.\n","- Afterwards, we will then print the table of outputs as a rich HTML table visualization.\n","\n","#### Steps to Complete:\n","- [ ] Set the sample_limit to an integer value of 100 so that no more than 100 data items will be collected from the dataset\n","- [ ] Create a for loop like you learned about from class so that you increment up to and including 100 data samples\n","- [ ] Use boolean operators to set the missing `load_dataset` parameters to `True`."],"metadata":{"id":"-JnJBzEUMQdq"}},{"cell_type":"code","source":["from datasets import load_dataset\n","import pandas as pd\n","\n","# Load the reviews dataset\n","reviews_dataset = load_dataset(\n","    \"McAuley-Lab/Amazon-Reviews-2023\",\n","    \"raw_review_Electronics\",\n","    split=\"full\",\n","    streaming=#<---- YOUR CODE GOES HERE ---->,\n","    trust_remote_code=#<---- YOUR CODE GOES HERE ---->\n",")\n","\n","# Initialize an empty list to collect review samples\n","reviews = []\n","\n","# Limit the number of data samples collected\n","sample_limit = #<---- YOUR CODE GOES HERE ---->\n","\n","# Iterate over the reviews dataset and collect samples\n","for #<---- YOUR CODE GOES HERE ---->\n","    if #<---- YOUR CODE GOES HERE ---->\n","        break\n","    reviews.append(#<---- YOUR CODE GOES HERE ---->)\n","\n","# Convert the list of review samples to a pandas DataFrame\n","reviews_df = pd.DataFrame(reviews)\n","\n","# Print the dataframe\n","reviews_df"],"metadata":{"id":"mUIiSmnyMRfX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Solution"],"metadata":{"id":"Xk_K224pMUys"}},{"cell_type":"code","source":["from datasets import load_dataset\n","import pandas as pd\n","\n","# Load the reviews dataset\n","reviews_dataset = load_dataset(\"McAuley-Lab/Amazon-Reviews-2023\", \"raw_review_Electronics\", split=\"full\", streaming=True, trust_remote_code=True)\n","\n","# Initialize an empty list to collect review samples\n","reviews = []\n","\n","# Limit to 100 samples\n","sample_limit = 100\n","\n","# Iterate over the reviews dataset and collect samples\n","for i, sample in enumerate(reviews_dataset):\n","    if i >= sample_limit:\n","        break\n","    reviews.append(sample)\n","\n","# Convert the list of review samples to a pandas DataFrame\n","reviews_df = pd.DataFrame(reviews)\n","\n","# Print the dataframe\n","reviews_df"],"metadata":{"id":"V6pf3SmtMVZ9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Let's Reflect..."],"metadata":{"id":"SQAmccDTN0vE"}},{"cell_type":"code","source":["#@title üí≠ Question to Answer:\n","#@markdown Describe the data that you see. What are the columns, what data types do you see, and how are the reviews structured?\n","Question1 = '' #@param {type:\"string\"}\n","\n","if len(Question1) > 0:\n","    print(f\"Question answered! You wrote: {Question1}\")\n","else:\n","    print(\"Please answer the question\")"],"metadata":{"cellView":"form","id":"dNU2xnFENyR8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Part 2.3: Analyze the reviews dataset with `.head()` from `pandas`\n","- In the above cell, when we wrote `reviews_df` - we printed the Amazon review data we downloaded as rich HTML outputs. Jupyter notebooks have many great data visualization tools, such as render the DataFrame as a rich HTML table, which is readable and visually appealing as it comes with pagination and the ability to show the first few and last few items in the DataFrame, making it visually interesting and interactive to work with.\n","\n","- There will be some times where this is sufficient, especially to get a nice visualzation, but there will be other times where you need to leverage `pandas` a bit more, such as quickly gathering the first few items of the DataFrame with a method called `.head()` which you will do in the subsequent cells.\n","\n","- The `.head()` method from `pandas` prints the DataFrame in a plain text format, which can be extremely useful for quickly inspecting the first few rows of the DataFrame without overwhelming the display with lots of data if you have a lot of columns or information to work with.\n","\n","Let's try out this new data inspection method!"],"metadata":{"id":"Ke5_mM8UOHHo"}},{"cell_type":"code","source":["print(reviews_df.head())"],"metadata":{"id":"PTwNBtJ_Oeic"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Let's Reflect..."],"metadata":{"id":"_H137KE5OqzX"}},{"cell_type":"code","source":["#@title üí≠ Question to Answer:\n","#@markdown What do you think of this output above - was this what you expected? Why or why not?\n","Question2 = '' #@param {type:\"string\"}\n","\n","if len(Question2) > 0:\n","    print(f\"Question answered! You wrote: {Question2}\")\n","else:\n","    print(\"Please answer the question\")"],"metadata":{"cellView":"form","id":"2FOFIFwCOpWY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Part 2.4 - Transform the DataFrame to be more visually readable\n","\n","As you work with data at Transformational AI, you will see that what we get from another team, department, or company will not be up to our standards. `Pandas` returned the data in 5 output blocks. You will notice that the items 0-4, mean that it's giving us the first 5 items in our dataset. This is what we would expect. However, wouldn't it be easier to see all the data for an item on the same line?\n","\n","Let's set some options for how `pandas` will output our dataframe. Remember from the course that you can set values, or options, for various structures. the `pd` `dataframe` is one of those that we can control the outputs for, such as:\n","- `max_columns`\n","- `width`\n","- `max_colwidth`\n","- and so on...\n","\n","#### Steps to Complete:\n","- [ ] Set the `Items_To_Print` value to an integer of `10` so that we only output the first 10 items of the DataFrame, overwriting Pandas' default output."],"metadata":{"id":"grEoNDfdOxDw"}},{"cell_type":"code","source":["import pandas as pd\n","\n","Items_To_Print = #<---- YOUR CODE GOES HERE ---->\n","\n","# Adjust display options for better readability\n","pd.set_option('display.max_columns', None)  # Display all columns\n","pd.set_option('display.width', 1000)        # Set a larger display width\n","pd.set_option('display.max_colwidth', 50)   # Set max column width for better readability\n","\n","# Assuming reviews_df is your DataFrame\n","print(reviews_df.head(10))"],"metadata":{"id":"Bfvu-4ToOzG2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Solution"],"metadata":{"id":"KMU6rGkYPY3F"}},{"cell_type":"code","source":["Items_To_Print = 10"],"metadata":{"id":"cst6jGSTPZeT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Let's Reflect..."],"metadata":{"id":"cKlpUqlaWsf7"}},{"cell_type":"code","source":["#@title üí≠ Question to Answer:\n","#@markdown Describe what we did to the pandas DataFrame in order to change how the outputs are reflected\n","Question3 = '' #@param {type:\"string\"}\n","\n","# Example of how to use the entered name\n","if len(Question3) > 0:\n","    print(f\"Question answered! You wrote: {Question3}\")\n","else:\n","    print(\"Please answer the question\")"],"metadata":{"cellView":"form","id":"Gth0ymQtPeLH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Part 3: Download the Reviews Metadata Dataset:\n","\n","In this next part, you will be reviewing the metadata associated with reviews. This will give us more topical information about the actual products we want to analyze."],"metadata":{"id":"XQ8BZqDwWEy8"}},{"cell_type":"markdown","source":["## Part 3.1: Download and visualize the reviews metadata dataset with `pandas`\n","\n","We will be working with a different dataset, specifically scoped on the metadata around the reviews. This will give us more numeric data about the products the machine learning team at Transformational AI wants to know more about.\n","\n","#### Steps to Complete:\n","- [ ] Set the metadata_limit to an integer value of 100 so that no more than 100 data items will be collected from the dataset\n","- [ ] Create a for loop like you learned about from class so that you increment up to and including 100 data samples\n","- [ ] Use boolean operators to set the missing `load_dataset` parameters to `True`."],"metadata":{"id":"ps5a5sZ1WIZ1"}},{"cell_type":"code","source":["from datasets import load_dataset\n","import pandas as pd\n","\n","# Load the item metadata dataset\n","item_metadata_dataset = load_dataset(\n","    \"McAuley-Lab/Amazon-Reviews-2023\",\n","    \"raw_meta_Electronics\",\n","    split=\"full\",\n","    streaming=#<---- YOUR CODE GOES HERE ---->,\n","    trust_remote_code=#<---- YOUR CODE GOES HERE ---->\n",")\n","\n","# Initialize an empty list to collect item metadata samples\n","metadata = []\n","\n","# Limit to 100 samples\n","metadata_limit = #<---- YOUR CODE GOES HERE ---->\n","\n","# Iterate over the metadata dataset and collect samples\n","for #<---- YOUR CODE GOES HERE ---->\n","    if #<---- YOUR CODE GOES HERE ---->\n","        break\n","    metadata.append(#<---- YOUR CODE GOES HERE ---->)\n","\n","# Convert the list of item metadata samples to a pandas DataFrame\n","item_metadata_df = pd.DataFrame(metadata)\n","\n","# Print the dataframe\n","item_metadata_df"],"metadata":{"id":"LIqO_grVWKaJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Solution"],"metadata":{"id":"dfUQ5d8uWWSE"}},{"cell_type":"code","source":["from datasets import load_dataset\n","import pandas as pd\n","\n","# Load the item metadata dataset\n","item_metadata_dataset = load_dataset(\"McAuley-Lab/Amazon-Reviews-2023\", \"raw_meta_Electronics\", split=\"full\", streaming=True, trust_remote_code=True)\n","\n","# Initialize an empty list to collect item metadata samples\n","metadata = []\n","\n","# Limit to 100 samples\n","metadata_limit = 100\n","\n","# Iterate over the metadata dataset and collect samples\n","for i, sample in enumerate(item_metadata_dataset):\n","    if i >= metadata_limit:\n","        break\n","    metadata.append(sample)\n","\n","# Convert the list of item metadata samples to a pandas DataFrame\n","item_metadata_df = pd.DataFrame(metadata)\n","\n","# Print the dataframe\n","item_metadata_df"],"metadata":{"id":"O763wi9EWZAn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Let's Reflect..."],"metadata":{"id":"r7GAsd4wWzpV"}},{"cell_type":"code","source":["#@title üí≠ Question to Answer:\n","#@markdown Compare the Reviews Metadata dataset (the dataset immediately above this cell) and the Reviews dataset that you analyzed earlier. What are the differences between the 2 datasets?\n","Question4 = '' #@param {type:\"string\"}\n","\n","if len(Question4) > 0:\n","    print(f\"Question answered! You wrote: {Question4}\")\n","else:\n","    print(\"Please answer the question\")"],"metadata":{"cellView":"form","id":"JdSXZasUWyqu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Part 3.2: Analyze the reviews metadata dataset with .head() from pandas\n","\n","We will now use the `.head()` method again to analyze the `pandas` dataframe."],"metadata":{"id":"xxWxhhOLW5r6"}},{"cell_type":"code","source":["print(item_metadata_df.head(10))"],"metadata":{"id":"OHiDP0xnW4jI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["^ Did you notice that now when we use the `.head()` method, our `pandas` output preferences were saved? This is the value of the Pythonic environment we are using, because as we set variables or settings declarations, they are preserved throughout the environment when we need to reference them again. This will save you lots of time as you continue your work here at Transformational AI."],"metadata":{"id":"W1_mP951XApU"}},{"cell_type":"markdown","source":["## Part 3.3: Safeguarding Data Access with Large Datasets\n","\n","Now that you are working with DataFrames and large datasets in Python, let's analyze our data a bit before moving on to the next section. Data analysis usually involves reviewing, investigating, or looking up specific information within the larger data context. However, this can lead to errors, especially if the data isn't formatted correctly, if data is missing, or if outputs aren't always consistent. As we work with Python, we will want to ensure our work remains robust and error-free at Transformational AI.\n","\n","Let's look at how to search for product prices and discover more about the item_metadata_df data that we imported into our Jupyter Notebook. We will need a function to handle situations where the product information might be missing to manage lookup and indexing errors that can arise.\n","\n","#### Steps to Complete:\n","- [ ] Review the items with and without a price\n","- [ ] Finish the `get_product` lookup function by handling the exception case where the product title or price is not found using try-except blocks\n"],"metadata":{"id":"vZMwtv4GXAPt"}},{"cell_type":"code","source":["import pandas as pd\n","\n","# Ensure the 'price' column is converted to numeric, setting errors='coerce' to handle non-numeric values\n","item_metadata_df['price'] = pd.to_numeric(item_metadata_df['price'], errors='coerce')\n","\n","# Identify products with 'None' or non-float prices\n","none_price_products = item_metadata_df[item_metadata_df['price'].isna()][['title', 'price']]\n","valid_price_products = item_metadata_df[item_metadata_df['price'].notna()][['title', 'price']]\n","\n","# Print the list of products with 'None' or non-float prices\n","print(f\"‚ùå Products with no valid price listed (Total: {len(none_price_products)})\")\n","for i, row in enumerate(none_price_products.itertuples(index=False), start=1):\n","    print(f\"{i}. {row.title} - Price: {row.price}\")\n","\n","# Print the list of products with valid prices\n","print(f\"\\n‚úÖ Products with valid price listed (Total: {len(valid_price_products)})\")\n","for i, row in enumerate(valid_price_products.itertuples(index=False), start=1):\n","    print(f\"{i}. {row.title} - Price: {row.price}\")"],"metadata":{"id":"8g1K_Q-Rqykz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Create a product lookup function with exception handling"],"metadata":{"id":"fzYysfrQrFTQ"}},{"cell_type":"code","source":["# Function to get the price of a product by its title\n","def get_product(product_title):\n","    try:\n","        # Attempt to find the price of the product\n","        price = item_metadata_df.loc[item_metadata_df['title'] == product_title, 'price'].values[0]\n","        if pd.isna(price):\n","            return \"‚ùå No valid price listed\"\n","        return price\n","    except IndexError:\n","        # Handle the case where the product title is not found\n","        #<---- YOUR CODE GOES HERE ---->"],"metadata":{"id":"79vB7p79rHez"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Solution"],"metadata":{"id":"9ZRnadOTrpvc"}},{"cell_type":"code","source":["# Function to get the price of a product by its title\n","def get_product(product_title):\n","    try:\n","        # Attempt to find the price of the product\n","        price = item_metadata_df.loc[item_metadata_df['title'] == product_title, 'price'].values[0]\n","        if pd.isna(price):\n","            return \"‚ùå No valid price listed\"\n","        return price\n","    except IndexError:\n","        # Handle the case where the product title is not found\n","        return \"‚ùå Product not found\""],"metadata":{"id":"7KHS76mdrrES"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Test the product lookup function (known product title)\n","Check a specific item (with a known product title) in the DataFrame with a lookup:"],"metadata":{"id":"iBHCn_vBq8kn"}},{"cell_type":"code","source":["known_title = \"FS-1051 FATSHARK TELEPORTER V3 HEADSET\"\n","print(f\"\\nPrice of '{known_title}': {get_product(known_title)}\")"],"metadata":{"id":"nlWD0dB2q3NO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Test the product lookup function (unknown product title)"],"metadata":{"id":"4Q7CQPOirMcX"}},{"cell_type":"code","source":["unknown_title = \"Smart Phone Tripod Holder (Mobile Version)\"\n","print(f\"Price of '{unknown_title}': {get_product(unknown_title)}\")"],"metadata":{"id":"GU2Gj8MWrTig"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Above, you can see how we can handle data access errors gracefully. By implementing exception handling in the `get_product` function, you can manage cases where the product title is not found or the price is missing, ensuring your code is robust and reliable."],"metadata":{"id":"IDFiMefntv4O"}},{"cell_type":"markdown","source":["# Part 4: Comparing our datasets together\n","\n","To get a better sense of these two datasets we just downloaded, let's review their columns. This will give us a better sense of the data structures involved, data types, and how we can use the datasets for which purposes."],"metadata":{"id":"VKTvhja-XGqn"}},{"cell_type":"markdown","source":["## Part 4.1 Review the columns of the datasets with `.columns`:\n","\n","In order to analyze the datasets quickly, we can leverage our `pandas` DataFrames several ways, such as looking at the `columns` in each dataset.\n","\n","#### STEPS TO COMPLETE:\n","Place the right variable in the right spot:\n","- [ ] `reviews_df.columns`\n","- [ ] `item_metadata_df.columns`"],"metadata":{"id":"1Gl5qqW1XI8U"}},{"cell_type":"code","source":["print(\"Reviews DataFrame columns:\", #<---- YOUR CODE GOES HERE ---->)\n","print(\"-------------------\")\n","print(\"Metadata DataFrame columns:\", #<---- YOUR CODE GOES HERE ---->)"],"metadata":{"id":"I-4Q8YTaXLmb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Solution:"],"metadata":{"id":"urD2K6f3Xftt"}},{"cell_type":"code","source":["print(\"Reviews DataFrame columns:\", reviews_df.columns)\n","print(\"Metadata DataFrame columns:\", item_metadata_df.columns)"],"metadata":{"id":"bFzZ4APRXhst"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The above is helpful, but it is a bit messy to read. Let's use our new skills to create a for loop to iterate over the items so that they can be outputted as a list.\n","\n","#### STEPS TO COMPLETE:\n","- [ ] Update the for loops to output the right information"],"metadata":{"id":"gGOGGXljXxvm"}},{"cell_type":"code","source":["print(\"Reviews DataFrame columns:\")\n","for #<---- YOUR CODE GOES HERE ---->\n","    print(f\"- {#<---- YOUR CODE GOES HERE ---->}\")\n","\n","print(\"-------------------\")\n","\n","print(\"Metadata DataFrame columns:\")\n","for #<---- YOUR CODE GOES HERE ---->\n","    print(f\"- {#<---- YOUR CODE GOES HERE ---->}\")"],"metadata":{"id":"AWOuKIVyX3QZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Solution:"],"metadata":{"id":"s_Y4qt69YCel"}},{"cell_type":"code","source":["# Print column names to debug\n","print(\"Reviews DataFrame columns:\")\n","for column in reviews_df.columns:\n","    print(f\"- {column}\")\n","\n","print(\"-------------------\")\n","\n","print(\"Metadata DataFrame columns:\")\n","for column in item_metadata_df.columns:\n","    print(f\"- {column}\")"],"metadata":{"id":"wk_5uOCUYB7d"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Part 4.2 Review the data types for each dataset with `.dtypes`\n","\n","Next, let's analyze what the \"data structure\" is for each item. If you remember from the course, data structures can be text (strings), number (integer, float, etc.), etc. They are the \"types\" that data can be used to compare or contrast against.\n","\n","For our purposes, we want to get a better sense of the data that we pulled into our environment for the Machine Learning team to later use."],"metadata":{"id":"ugCgLdNVYSvB"}},{"cell_type":"code","source":["# Print column names and their data types using .dtypes\n","print(\"Reviews DataFrame columns and data types:\")\n","print(reviews_df.dtypes)\n","\n","print(\"-------------------\")\n","\n","print(\"Metadata DataFrame columns and data types:\")\n","print(item_metadata_df.dtypes)"],"metadata":{"id":"26d2eGdsYYhs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The above is helpful, but let's use a for loop to iterate over the items so that they can be outputted as a list:"],"metadata":{"id":"aBL9IAEkYgka"}},{"cell_type":"code","source":["# Print column names and their data types\n","print(\"Reviews DataFrame columns and data types:\")\n","for column in reviews_df.columns:\n","    print(f\"- {column}: {reviews_df[column].dtype}\")\n","\n","print(\"-------------------\")\n","\n","print(\"Metadata DataFrame columns and data types:\")\n","for column in item_metadata_df.columns:\n","    print(f\"- {column}: {item_metadata_df[column].dtype}\")"],"metadata":{"id":"_yGXPMlNYiqu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Part 4.3 Create a concise summary of a DataFrame with `.info()`\n","\n","While you were analyzing your data, your manager messages you asking for a quick summary of the breakdown between the summaries in the next 15 minutes. Scrambling to what to do, you remember that you can use the `.info()` method from `pandas` to get your manager exactly what they need.\n","\n","- If you remember from class, a `method` in Python is a function that is associated with an object. `.info()` is method of the pandas DataFrame class where when you call `something_df.info()`, you are invoking the \"info\" method on the `something_df` object, which is an instance of a DataFrame.\n","- Also, if you recall from class, the act of calling a method (like `.info()`) on an object (like `something_df`) is known as method `invocation`, which is fundamental to how Python works as an object-oriented programming language.\n","\n","#### STEPS TO COMPLETE:\n","- [ ] Print the info for the `reviews_df` DataFrame\n","- [ ] Print the info for the `item_metadata_df` DataFrame"],"metadata":{"id":"gXyh0WUKYrA6"}},{"cell_type":"code","source":["# Print DataFrame info which includes data types\n","print(\"Reviews DataFrame info:\")\n","#<---- YOUR CODE GOES HERE ---->\n","\n","print(\"-------------------\")\n","\n","print(\"Metadata DataFrame info:\")\n","#<---- YOUR CODE GOES HERE ---->"],"metadata":{"id":"uEpKSgfyZOsC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Solution"],"metadata":{"id":"sJ7X5J1SaIme"}},{"cell_type":"code","source":["# Print DataFrame info which includes data types\n","print(\"Reviews DataFrame info:\")\n","reviews_df.info()\n","\n","print(\"-------------------\")\n","\n","print(\"Metadata DataFrame info:\")\n","item_metadata_df.info()"],"metadata":{"id":"3HvKgIOCaKF5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## ^ Phew! üòÖ That was a close call.\n","But fortunately for us, `pandas` comes with a lot of out of the box utilities for data analysis and data visualization that we might need to tweak or fine-tune to our usecases but without too much headache. Let's get back to our work at hand.\n","\n","Great work!!"],"metadata":{"id":"HdeqxAjuay5u"}},{"cell_type":"markdown","source":["## Let's Reflect..."],"metadata":{"id":"TILuTYg0a61y"}},{"cell_type":"code","source":["#@title üí≠ Question to Answer:\n","#@markdown Which data analysis method you find to be the most insightful or helpful?\n","Question5 = '' #@param {type:\"string\"}\n","\n","if len(Question5) > 0:\n","    print(f\"Question answered! You wrote: {Question5}\")\n","else:\n","    print(\"Please answer the question\")"],"metadata":{"cellView":"form","id":"_3arqGmGa8EN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Part 5: Preparing the data for the Machine Learning Team\n","\n","Now that we are comfortable with our datasets and have a good sense of what we can leverage, the Machine Learning team has just informed you that they need to know what the top products are to train their advanced machine learning model on.\n","\n","You will be further cleaning and transforming the data so that you can create an informed, data-driven decision about what products are most important to the team.\n","\n","So where would we start? Let's assume that we need a threshold value in order to separate what makes a good product from a great product. If you remember from earlier, on the metadata\n","\n","- `title`: we need to know the product\n","-\t`average_rating`: we need to know if the product is above the treshold we set (4.5 or above)\n","- `price`: we need a real monetary price value. Notice how sometimes it could be NONE. We need something that is number with a decimal. (0.01 and above)\n"],"metadata":{"id":"1PQxIeGRbCa5"}},{"cell_type":"markdown","source":["## Part 5.1: Clean the data for the requested parameters\n","\n","We will create a new DataFrame called `top_products_df` with these parameters:\n","- has a title\n","- the average rating is greater than or equal to 4.5\n","- there is a value for the price\n","\n","#### STEPS TO COMPLETE:\n","- [ ] Specify the 3 columns we want in the new dataframe `item_metadata_cleaned_df`\n","- [ ] Set the `average_rating_filter` variable to the correct float data type that is sought after in the instructions above"],"metadata":{"id":"7LrYyZ6RbHJk"}},{"cell_type":"code","source":["# Select relevant columns\n","item_metadata_cleaned_df = item_metadata_df[[#<---- YOUR CODE GOES HERE ---->]]\n","average_rating_filter = #<---- YOUR CODE GOES HERE ---->\n","\n","# Convert the price column to numeric, setting errors='coerce' to handle non-numeric values\n","item_metadata_cleaned_df['price'] = pd.to_numeric(item_metadata_cleaned_df['price'], errors='coerce')\n","\n","# Filter to get only products with average rating set to the filter, valid price, and non-null title\n","top_products_df = item_metadata_cleaned_df[\n","    (item_metadata_cleaned_df['average_rating'] >= average_rating_filter) &\n","    (item_metadata_cleaned_df['price'].notna()) &\n","    (item_metadata_cleaned_df['title'].notna())\n","]\n","\n","# Print the new cleaned DataFrame\n","top_products_df"],"metadata":{"id":"BOC3yg05bKVW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Solution"],"metadata":{"id":"uf-sNLqHbWwM"}},{"cell_type":"code","source":["# Select relevant columns\n","item_metadata_cleaned_df = item_metadata_df[['title', 'average_rating', 'price']]\n","average_rating_filter = 4.5\n","\n","# Convert the price column to numeric, setting errors='coerce' to handle non-numeric values\n","item_metadata_cleaned_df['price'] = pd.to_numeric(item_metadata_cleaned_df['price'], errors='coerce')\n","\n","# Filter to get only products with average rating set to the filter, valid price, and non-null title\n","top_products_df = item_metadata_cleaned_df[\n","    (item_metadata_cleaned_df['average_rating'] >= average_rating_filter) &\n","    (item_metadata_cleaned_df['price'].notna()) &\n","    (item_metadata_cleaned_df['title'].notna())\n","]\n","\n","# Print the new cleaned DataFrame\n","top_products_df"],"metadata":{"id":"e56RkikTbX-4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Part 5.2: Analyze the data using pandas\n","\n","Let's find out how many products are in this new cleaned dataset."],"metadata":{"id":"LocqhW5IcJCk"}},{"cell_type":"code","source":["# Review the items of the original dataframe\n","num_items_original = item_metadata_df.shape[0]\n","print(f\"Number of items in the original DataFrame: {num_items_original}\")\n","\n","# Review the new items in cleaned dataframe\n","num_items_cleaned = top_products_df.shape[0]\n","print(f\"Number of items in the cleaned DataFrame: {num_items_cleaned}\")"],"metadata":{"id":"A2qTY54dcISW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Part 5.3: Calculate the Percentage of Cleaned Data\n","\n","You should see that the number of items in the cleaned DataFrame is much smaller than the number of items in the original DataFrame. Let's calculate the percentage of items in the cleaned DataFrame relative to the original DataFrame.\n","\n","#### STEPS TO COMPLETE:\n","- [ ] Complete the function `calculate_percentage` to perform this calculation. Use your knowledge from the course to write a part-of-whole division equation.\n","- [ ] Ensure to use the `return` keyword so that your `calculate_percentage` function returns the result."],"metadata":{"id":"L0hYadGtcq6Y"}},{"cell_type":"code","source":["# Input from user\n","part = float(input(\"Enter the number of items in the cleaned DataFrame: \"))\n","whole = float(input(\"Enter the number of items in the original DataFrame: \"))\n","\n","# Function to calculate percentage\n","def calculate_percentage(part, whole):\n","    if whole == 0:\n","        raise ValueError(\"The whole value cannot be zero.\")\n","\n","    # Calculate the percentage\n","    percentage = #<---- YOUR CODE GOES HERE ---->\n","    return #<---- YOUR CODE GOES HERE ---->\n","\n","# Calculate and print the percentage\n","try:\n","    result = calculate_percentage(part, whole)\n","    print(f\"{part} is {result:.2f}% of {whole}\")\n","except ValueError as e:\n","    print(e)"],"metadata":{"id":"3vTg7UjSc6ii"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Solution:"],"metadata":{"id":"D4CuTASudlnB"}},{"cell_type":"code","source":["# Function to calculate percentage\n","def calculate_percentage(part, whole):\n","    if whole == 0:\n","        raise ValueError(\"The whole value cannot be zero.\")\n","\n","    # Calculate the percentage\n","    percentage = (part / whole) * 100\n","    return percentage"],"metadata":{"id":"tCUa2Ug8dm7h"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Part 5.4: Package the dataset up for analysis (.csv)\n","\n","In order to save our new dataset, let's package it up into a `.csv` file so that your team at Transformational AI can analyze the outputs you found."],"metadata":{"id":"mhkOJFX_er3q"}},{"cell_type":"code","source":["# Save the DataFrame as a CSV file\n","top_products_df.to_csv('top_products.csv', index=False)\n","\n","# Verify that the file is saved\n","!ls -lh top_products.csv"],"metadata":{"id":"PmAsZVsPevOR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Part 5.5: Package the dataset up for analysis (.parquet)\n","\n","You might find that various team members need data saved in particular ways. For example, dependending on how data is coordinated or analyzed, `.csv` might not cut it. There is a movement to move towards size-saving strategies, which can mean saving data in other formats.\n","\n","Luckily, your team member at Transformational AI gave you a heads up about the team's love for the `.parquet` format. In order to impress your team and new manager, you have just enough time to transform your data outputs into this format."],"metadata":{"id":"A-UYy9dze0th"}},{"cell_type":"code","source":["# Ensure pyarrow or fastparquet is installed\n","!pip install pyarrow"],"metadata":{"id":"4b-YxrP9e4Ui"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Save the DataFrame as a Parquet file\n","top_products_df.to_parquet('top_products.parquet', index=False)\n","\n","# Verify that the file is saved\n","!ls -lh top_products.parquet"],"metadata":{"id":"-5y-mAURe45Z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Really great work! ü•≥ You'll now be able to send both files along to the teams, one for easy visualization (`.csv`), and one for easy data use (`.parquet`)"],"metadata":{"id":"ELEQBQsxe73G"}},{"cell_type":"markdown","source":["## Part 5.6: Collect the Top Rated Product Titles\n","\n","When working with large datasets like the reviews datasets we are using, we might need to handle the data with lists and exceptions. These are fundamental Python skills that are important to know and have in your toolbox.\n","\n","- Lists are a type of data structure that let's us store multiple items as a single variable\n","- To work with them, we will use the `append` method to collect the data and \"add\" it to a single variable to reference it in our work.\n","- In this case, we will be pulling out the titles from our `highly_rated_products_df` DataFrame and storing those in our list, which we will create and name `top_rated_titles`.\n","\n","#### STEPS TO COMPLETE:\n","- [ ] Create an empty array called `top_rated_titles` which will be our list.\n","- [ ] Create a for loop to iterate over the `highly_rated_products_df` DataFrame and then use the `.append` method for the titles to add them to the `top_rated_titles` list\n","- [ ] Print the results of the `top_rated_titles` list"],"metadata":{"id":"PeP-yJzsRO3K"}},{"cell_type":"code","source":["# Initialize an empty list to collect top-rated product titles\n","#<---- YOUR CODE GOES HERE ---->\n","\n","# Create a for loop to iterate over the highly_rated_products_df DataFrame\n","# Use the `append` method for the titles to add them to the `top_rated_titles` list\n","#<---- YOUR CODE GOES HERE ---->\n","\n","# Print the list of top-rated product titles\n","print(\"List of Top-Rated Product Titles:\")\n","#<---- YOUR CODE GOES HERE ---->"],"metadata":{"id":"YtC6C5aTR6s5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Solution:"],"metadata":{"id":"wekmU5wxSjrW"}},{"cell_type":"code","source":["# Initialize an empty list to collect top-rated product titles\n","top_rated_titles = []\n","\n","# Create a for loop to iterate over the highly_rated_products_df DataFrame\n","# Use the `append` method for the titles to add them to the `top_rated_titles` list\n","for title in highly_rated_products_df['title']:\n","    top_rated_titles.append(title)\n","\n","# Print the list of top-rated product titles\n","print(\"List of Top-Rated Product Titles:\")\n","print(top_rated_titles)"],"metadata":{"id":"yLSgLgd9SlyR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Part 5.7: Transforming our List Data\n","You might notice that when we print the values, it becomes a very long string. This is because lists become a comma separated long string, enclosed in square brackets. This is a default behavior of Python, which can be efficient to work with in certain cases. However, let's make the list a bit more human readable.\n","\n","Something we can do is iterate through the list and print each item in the list separately and add numbers or bullet points to each element.\n","\n","Run the following cell to do this:"],"metadata":{"id":"aVTY1U-9T7pO"}},{"cell_type":"code","source":["for i, title in enumerate(top_rated_titles, start=1):\n","    print(f\"{i}. {title}\")"],"metadata":{"id":"zuN4ao6qUi2s"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["^ This looks much better and easier to read. Great work!"],"metadata":{"id":"IqXfQuZfUsIX"}},{"cell_type":"markdown","source":["# Part 6: Visualize the data for the Business Team\n","\n","To visualize our data, we will be using a Histogram. Histograms are a type of graph that coordinates groups of data points into user-specified ranges (bins). Each bar in a histogram represents the frequency (the count) of data points that fall within each range.\n","\n","We will also be using a Scatterplot graph, which will show the exact points that the histogram creates groupings of."],"metadata":{"id":"7LB-PyzhfARv"}},{"cell_type":"markdown","source":["## Part 6.1: Map the distribution of Prices for Highly Rated Products as a Histogram Chart\n","In this graph, we will want to see if there is a trend for price and ratings, specifically to visualize the distribution of prices for highly rated products (those with an average rating of 4.5 or higher).\n","\n","#### STEPS TO COMPLETE:\n","- [ ] Use the `top_products_df` dataframe for the histogram graph\n","- [ ] Use the `price` column from the `top_products_df`\n","- [ ] Use a boolean operator to set the missing `sns.histplot` parameter `kde`  to `True`.\n"],"metadata":{"id":"nvvDxxaKfCqD"}},{"cell_type":"code","source":["import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","# Distribution of Prices\n","plt.figure(figsize=(10, 6))\n","sns.histplot(\n","    <---- YOUR CODE GOES HERE ----> ['<---- YOUR CODE GOES HERE ---->'],\n","    bins=30,\n","    kde=#<---- YOUR CODE GOES HERE ---->\n",")\n","plt.title('Distribution of Prices for Highly Rated Products')\n","plt.xlabel('Price')\n","plt.ylabel('Frequency of Rating')\n","plt.show()"],"metadata":{"id":"_zjo6qAqfGil"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Solution"],"metadata":{"id":"1nGTaaJIfWb2"}},{"cell_type":"code","source":["import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","# Distribution of Prices\n","plt.figure(figsize=(10, 6))\n","sns.histplot(top_products_df['price'], bins=30, kde=True)\n","plt.title('Distribution of Prices for Highly Rated Products')\n","plt.xlabel('Price')\n","plt.ylabel('Frequency of Rating')\n","plt.show()"],"metadata":{"id":"-9w2H70yfX-o"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Let's Reflect..."],"metadata":{"id":"CLPKaiuXfk_A"}},{"cell_type":"code","source":["#@title üí≠ Question to Answer:\n","#@markdown What trend (if any) do you notice with price and frequency\n","Question6 = '' #@param {type:\"string\"}\n","\n","if len(Question6) > 0:\n","    print(f\"Question answered! You wrote: {Question6}\")\n","else:\n","    print(\"Please answer the question\")"],"metadata":{"cellView":"form","id":"qswEhNPHfkPO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Part 6.2: Map the distribution of Prices for Highly Rated Products as a Scatterplot Graph\n","In this graph, we will want to see if there is a trend for price and ratings, specifically to visualize the distribution of prices for highly rated products (those with an average rating of 4.5 or higher) as a scatterplot, rather than a histogram\n","\n","#### STEPS TO COMPLETE:\n","- [ ] Use the `top_products_df` dataframe for the scatterplot graph\n","- [ ] Plot you graph with the `price` for the x axis and `average_rating` on the y axis"],"metadata":{"id":"Lhmxzbwhfsv4"}},{"cell_type":"code","source":["# Average Rating vs. Price\n","plt.figure(figsize=(10, 6))\n","sns.scatterplot(data=<......>, x='<---- YOUR CODE GOES HERE ---->', y='<---- YOUR CODE GOES HERE ---->')\n","plt.title('Average Rating vs. Price')\n","plt.xlabel('Price')\n","plt.ylabel('Average Rating')\n","plt.show()"],"metadata":{"id":"CbxOCsXbfpcA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Solution:"],"metadata":{"id":"9sulgxAPf677"}},{"cell_type":"code","source":["# Average Rating vs. Price\n","plt.figure(figsize=(10, 6))\n","sns.scatterplot(data=top_products_df, x='price', y='average_rating')\n","plt.title('Average Rating vs. Price')\n","plt.xlabel('Price')\n","plt.ylabel('Average Rating')\n","plt.show()"],"metadata":{"id":"n7ZvHg0lf8Jf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Let's Reflect..."],"metadata":{"id":"MmZ5d7MRgPye"}},{"cell_type":"code","source":["#@title üí≠ Question to Answer:\n","#@markdown What trend (if any) do you notice with price and rating\n","Question7 = '' #@param {type:\"string\"}\n","\n","if len(Question7) > 0:\n","    print(f\"Question answered! You wrote: {Question7}\")\n","else:\n","    print(\"Please answer the question\")"],"metadata":{"cellView":"form","id":"0sPByaxBgPGB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Part 6.3: Display the distribution of ratings and price together\n","\n","The \"frequency\" in this context of a histogram or distribution plot refers to the number of times a particular value or range of values appears in the dataset. In our case, we want to know how often the ratings are coming up related to the price.\n","\n","For business-facing teams, showing data a couple different ways can be quite helpful, so we will want to visualize these 2 graphs together for maximum impact."],"metadata":{"id":"-VlRyuVigUit"}},{"cell_type":"code","source":["# Create a Dashboard Layout\n","plt.figure(figsize=(15, 10))\n","\n","# Subplot 1: Distribution of Prices\n","plt.subplot(2, 2, 1)\n","sns.histplot(top_products_df['price'], bins=30, kde=True)\n","plt.title('Distribution of Prices for Highly Rated Products')\n","plt.xlabel('Price')\n","plt.ylabel('Frequency of Rating')\n","\n","# Subplot 2: Average Rating vs. Price\n","plt.subplot(2, 2, 2)\n","sns.scatterplot(data=top_products_df, x='price', y='average_rating')\n","plt.title('Average Rating vs. Price')\n","plt.xlabel('Price')\n","plt.ylabel('Average Rating')\n","\n","# Feel free to add other visualizations as you like\n","\n","# Show the Dashboard\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"GXXG-OuDgXMd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 6.4: Narrow down on the handful of products that will be most meaningful\n","\n","To get a better sense of what products the teams will specifically want to double down on, let's use these graphs to create even better outputs.\n","\n","#### STEPS TO COMPLETE:\n","- [ ] Specify a cutoff threshold for the results as float data type `4.7`"],"metadata":{"id":"6wEBobLFge8F"}},{"cell_type":"code","source":["# Filter the DataFrame to include only products with an average rating of 4.7 or higher\n","average_rating_cutoff = #<---- YOUR CODE GOES HERE ---->\n","highly_rated_products_df = top_products_df[top_products_df['average_rating'] >= average_rating_cutoff]\n","\n","# Display the filtered DataFrame\n","print(highly_rated_products_df)"],"metadata":{"id":"9QK538pKghU7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Solution"],"metadata":{"id":"Vrq7VXOqgsxV"}},{"cell_type":"code","source":["# Filter the DataFrame to include only products with an average rating of 4.7 or higher\n","average_rating_cutoff = 4.7\n","highly_rated_products_df = top_products_df[top_products_df['average_rating'] >= average_rating_cutoff]\n","\n","# Display the filtered DataFrame\n","print(highly_rated_products_df)"],"metadata":{"id":"jPWvCaRXgukH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[" Count the number of items in the newly cleaned dataset"],"metadata":{"id":"uXSsdfg8g6fA"}},{"cell_type":"code","source":["# Review the new items in cleaned dataframe\n","highly_rated_num_items = highly_rated_products_df.shape[0]\n","print(f\"Number of items in the highly rated DataFrame: {highly_rated_num_items}\")"],"metadata":{"id":"u2T6OKmLg5UU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Calculate the percentage of the newly cleaned items with the function you wrote earlier:"],"metadata":{"id":"3ShzEyrehNhT"}},{"cell_type":"code","source":["# Input from user\n","part = float(input(\"Enter the number of items in the highly rated DataFrame: \"))\n","whole = float(input(\"Enter the number of items in the original top products DataFrame: \"))\n","\n","\n","# Calculate and print the percentage\n","try:\n","    result = calculate_percentage(part, whole)\n","    print(f\"{part} is {result:.2f}% of {whole}\")\n","except ValueError as e:\n","    print(e)"],"metadata":{"id":"FHB0tjykhJmP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Plot the new Histogram distribution with your highly rated DataFrame:"],"metadata":{"id":"OxHugV9phpEW"}},{"cell_type":"code","source":["plt.figure(figsize=(10, 6))\n","sns.histplot(highly_rated_products_df['price'], bins=30, kde=True)\n","plt.title('Distribution of Prices for Products with Rating 4.7 or Higher')\n","plt.xlabel('Price')\n","plt.ylabel('Frequency')\n","plt.show()"],"metadata":{"id":"LAduyvOzhsW2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Plot the new Scatterplot graph with your new highly rated DataFrame:"],"metadata":{"id":"gwpXqOgkhwCf"}},{"cell_type":"code","source":["plt.figure(figsize=(10, 6))\n","sns.scatterplot(data=highly_rated_products_df, x='price', y='average_rating')\n","plt.title('Average Rating vs. Price for Products with Rating 4.7 or Higher')\n","plt.xlabel('Price')\n","plt.ylabel('Average Rating')\n","plt.show()"],"metadata":{"id":"UKxeGYoth0EM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 6.5: Create a Dashboard of Your New Findings\n","The next step will be to create a dashboard for these new results so that you can share this with the Machine Learning, Business, and Executive teams. This section will involve filtering, sorting, and visualizing data, which are key skills covered in the PCEP syllabus.\n","\n","To accomplish this, we'll:\n","- Filter the DataFrame: We'll filter the DataFrame to include only products with an average rating of `4.7` or higher.\n","- Sort the DataFrame: We'll use the `.sort_values` method to sort the DataFrame by average rating in descending order.\n","- Display the DataFrame: We'll display the sorted DataFrame as a table.\n","- Create a Scatterplot: We'll create a scatterplot to visualize the relationship between price and average rating for the highly rated products.\n","\n","#### STEPS TO COMPLETE:\n","- [ ] Set the `highly_rated_products_df_cutoff` with the desired float threshold value\n","- [ ] Update the `highly_rated_products_df` to use the `.sort_values` method like you learned in class.\n","- [ ] Fill in the code to display the new sorted DataFrame\n","- [ ] Complete the code to create a scatterplot using Seaborn."],"metadata":{"id":"8IcsCGK9hzjF"}},{"cell_type":"code","source":["import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from IPython.display import display\n","\n","# Filter the DataFrame to include only products with an average rating of 4.7 or higher\n","highly_rated_products_df_cutoff = #<---- YOUR CODE GOES HERE ---->\n","highly_rated_products_df = top_products_df[top_products_df['average_rating'] >= highly_rated_products_df_cutoff]\n","\n","# Sort the DataFrame by average_rating in descending order\n","highly_rated_products_df = highly_rated_products_df.#<---- YOUR CODE GOES HERE ---->(by='average_rating', ascending=False)\n","\n","# Display the sorted DataFrame as a table\n","print(\"Table of Highly Rated Products (Rating 4.7 or Higher, Sorted by Rating):\")\n","display(#<---- YOUR CODE GOES HERE ---->)\n","\n","# Create the scatterplot\n","plt.figure(figsize=(10, 6))\n","sns.scatterplot(data=highly_rated_products_df, x='price', y='average_rating')\n","plt.title('Average Rating vs. Price for Products with Rating 4.7 or Higher')\n","plt.xlabel('Price')\n","plt.ylabel('Average Rating')\n","plt.show()"],"metadata":{"id":"L-i37zE4h9N4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Solution:"],"metadata":{"id":"37zZ-exukbxm"}},{"cell_type":"code","source":["import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from IPython.display import display\n","\n","# Filter the DataFrame to include only products with an average rating of 4.7 or higher\n","highly_rated_products_df_cutoff = 4.7\n","highly_rated_products_df = top_products_df[top_products_df['average_rating'] >= highly_rated_products_df_cutoff]\n","\n","# Sort the DataFrame by average_rating in descending order\n","highly_rated_products_df = highly_rated_products_df.sort_values(by='average_rating', ascending=False)\n","\n","# Display the sorted DataFrame as a table\n","print(\"Table of Highly Rated Products (Rating 4.7 or Higher, Sorted by Rating):\")\n","display(highly_rated_products_df)\n","\n","# Create the scatterplot\n","plt.figure(figsize=(10, 6))\n","sns.scatterplot(data=highly_rated_products_df, x='price', y='average_rating')\n","plt.title('Average Rating vs. Price for Products with Rating 4.7 or Higher')\n","plt.xlabel('Price')\n","plt.ylabel('Average Rating')\n","plt.show()"],"metadata":{"id":"5rPKql4akdw3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Amazing job!! You did it! ü•≥ üéâ"],"metadata":{"id":"BPXuTeChmTSa"}},{"cell_type":"markdown","source":["# üéÅ Wrap Up\n","\n","Congratulations, you completed everything that the Machine Learning Team, the Business Team, and the Executive Team at Transformational AI need to get started. You completed this in record time and your manager is excited to offer you a promotion to the Data Science team thanks to all of your hard work! ü•á\n","\n","To wrap up your excellent work, let's output all of your responses to the questions earlier into a `.txt` file. The code is already written for you, but let's look at what is happening:\n","- We create an `array` of questions to group all of your data inputs together\n","- We create a file name as a string called `output_file` where your responses will be written to.\n","- We write a for loop to iterate over each question, which lives inside of a with statement so that we can write each question and response as a line in the text file\n","- We use the `print` command to let us know when the file has been created and stored in our notebook."],"metadata":{"id":"uQSfsP5mQMl4"}},{"cell_type":"code","source":["#@title üí≠ Add your name\n","#@markdown Write your first and last name here\n","Name = '' #@param {type:\"string\"}\n","\n","if len(Name) > 0:\n","    print(f\"You added your name: {Name}\")\n","else:\n","    print(\"Please answer the question\")"],"metadata":{"cellView":"form","id":"Lcq0rkF5TLeG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Collect all the questions into a list\n","questions = [Question1, Question2, Question3, Question4, Question5, Question6, Question7]\n","\n","# Define the file name where your answers will be saved to\n","output_file = 'user_inputs.txt'\n","\n","# Write the project details and questions to the output file\n","with open(output_file, 'w') as file:\n","    # Write the project title and your name\n","    file.write(\"Transformational AI: Analyzing Ecommerce Large Datasets for Machine Learning\\n\")\n","    file.write(f\"Completed by: {Name}\\n\")\n","    file.write(\"‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî-\\n\\n\")\n","\n","    # Write each question and its response on subsequent line\n","    for i, question in enumerate(questions, start=1):\n","        file.write(f\"Question {i}: {question}\\n\")\n","\n","print(f\"All questions have been written to {output_file}\")"],"metadata":{"id":"pr3g-ZNcQGtG"},"execution_count":null,"outputs":[]}]}
